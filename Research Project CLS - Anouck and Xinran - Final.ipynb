{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcdn_SksdkRc"
   },
   "source": [
    "# CLS Sentiment analysis horror books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21068,
     "status": "ok",
     "timestamp": 1750687273228,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "NXMxBSBjhHou",
    "outputId": "067c4890-934d-4724-d0e1-430d6058bdc5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/CLS_Shared_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8369,
     "status": "ok",
     "timestamp": 1750687283803,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "F1maW1vOdkpJ",
    "outputId": "f5dc07e4-3c5b-458c-e9bf-312c77926022"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHPLugKrgydH"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t97EjvMliyc5"
   },
   "source": [
    "Read the json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1750687294034,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "7eK6-u1Ag9RJ",
    "outputId": "20e03086-a541-4f51-b2f5-170600d56bea"
   },
   "outputs": [],
   "source": [
    "#the json file is a list of dictionaries. Each dictionary stands for one story.\n",
    "with open('horror_tales_data_complete.json') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1750687294517,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "atzj77yigvAE",
    "outputId": "750163d0-1e06-46a6-c42e-dce90f2c08fa"
   },
   "outputs": [],
   "source": [
    "#Create dataframe\n",
    "horror = pd.DataFrame(corpus)\n",
    "\n",
    "# convert year to numeric\n",
    "horror['year'] = pd.to_numeric(horror['year'], errors='coerce')\n",
    "\n",
    "horror.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JsLSsfpGjti"
   },
   "source": [
    "Extract the titles, lengths and the unpreprocessed, raw text of the stories from the dataframe as lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750687294528,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "XcmDEdWXGdZi",
    "outputId": "ac8b1a57-1037-4779-c0c0-ba6bb3eab970"
   },
   "outputs": [],
   "source": [
    "stories = [] #list of stories (raw text)\n",
    "titles = [] #list of matching titles\n",
    "length = [] #list of lengths\n",
    "for index, row in horror.iterrows():\n",
    "  stories.append(row['text'])\n",
    "  titles.append(row['title'])\n",
    "  length.append(row['length'])\n",
    "\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750687294539,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "KGBO1BNdGieX",
    "outputId": "054118e0-e2e1-4948-8df2-082e247893e2"
   },
   "outputs": [],
   "source": [
    "# check if the number of titles and stories match\n",
    "print(len(titles))\n",
    "print(len(stories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEzIQ_BbAPl8"
   },
   "source": [
    "Inspecting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1750687294683,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "BdpgB6kNgvNO",
    "outputId": "d8629dfe-42a1-40ee-ed29-3aa40ad5e26f"
   },
   "outputs": [],
   "source": [
    "#inspecting the dataset to make sure everything is correct\n",
    "print(len(horror))\n",
    "horror['length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1750687294916,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "QlnRQLF7ANak",
    "outputId": "ecab4d02-cd7e-4794-ed77-a45c32823d5d"
   },
   "outputs": [],
   "source": [
    "horror[['author1', 'author2']].value_counts()[:20][::-1].plot.barh(figsize=(8, 12));\n",
    "#the 20 most frequent authors in the dataset\n",
    "#we can see that 17 \"sets of\" authors wrote more than one text of our dataset;\n",
    "#Bishop and Lovecraft collaborated on 2 texts, and the rest 16 are single authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT2gs1tR8wkw"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1750687298559,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "-P2SGdzT8n_Q",
    "outputId": "85f5e163-6d19-449e-d067-bef7b096773d"
   },
   "outputs": [],
   "source": [
    "horror['text'] = horror['text'].str.lower().str.strip() #lowercase and remove leading/trailing whitespaces\n",
    "horror['text'] = [' '.join(t.split()) for t in horror['text']] #split at whitespace and join with ' ' to remove additional whitespaces\n",
    "horror['text'] = [''.join([c for c in t if (c.isalpha() or c.isspace())]) for t in horror['text']]\n",
    "horror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "executionInfo": {
     "elapsed": 1431,
     "status": "ok",
     "timestamp": 1750687299993,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "7HzxtcXs8oBf",
    "outputId": "28d1c355-78ac-412c-d4bd-84123e61a372"
   },
   "outputs": [],
   "source": [
    "#bag-of-words model\n",
    "horror['bow'] = horror['text'].str.split().apply(Counter)\n",
    "horror.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZcpz3yIUN3A"
   },
   "source": [
    "## Analysis based on positive/negative sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARqpfPt-B4-2"
   },
   "source": [
    "### NRC Lexicon and look-up dictionary (pos/neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1750687300225,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "3Id-1aOT8oD-",
    "outputId": "94528a1d-9258-4c88-ef77-e21721fc2322"
   },
   "outputs": [],
   "source": [
    "emo = pd.read_csv('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None)\n",
    "emo.columns = ['word', 'emotion', 'score']\n",
    "emo = emo[emo['emotion'].isin({'positive', 'negative'})] #limit to 'positive' and 'negative'\n",
    "emo = emo[emo['score'] != 0]\n",
    "emo.sample(5)   #df with word and corresponding negative or positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1750687300640,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "w9t5uEmNm0Gp",
    "outputId": "29d10824-8cd8-407a-b369-0e69ff027214"
   },
   "outputs": [],
   "source": [
    "#inspect the words that are positive and negative at the same time: not many/frequent\n",
    "word_counts = emo['word'].value_counts()\n",
    "count = 0\n",
    "# Filter for words that appear exactly twice\n",
    "words_with_two = word_counts[word_counts == 2].index\n",
    "for index, row in emo.iterrows():\n",
    "    if row['word'] in words_with_two:\n",
    "      count += 1\n",
    "      print(row)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750687300647,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "MrEsm3Q38oI-"
   },
   "outputs": [],
   "source": [
    "#note: The following dictionary also takes into account when multiple emotions (positive AND negative) are associated with a word\n",
    "emotions = emo['emotion'].unique()\n",
    "emo_lookup = defaultdict(list)\n",
    "\n",
    "for w, e in zip(emo['word'], emo['emotion']):\n",
    "  emo_lookup[w].append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1750687300672,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "hbYJWsSq8oNn",
    "outputId": "f4343d00-77da-4069-a6bf-ee6e2b66ec96"
   },
   "outputs": [],
   "source": [
    "#test\n",
    "for word in 'love hate adore teens'.split():\n",
    "    print(word, ':', emo_lookup[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1750687301216,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "cUZbPrcq8oP_",
    "outputId": "53cbf615-b102-4f31-c91f-dc27997b691a"
   },
   "outputs": [],
   "source": [
    "emo_presence = []\n",
    "\n",
    "for story in tqdm(horror['bow']):\n",
    "    story_emotions = Counter()\n",
    "    for word in story:\n",
    "      if word in emo_lookup:   #this needs to be added, not every word is in our lookup dictionary\n",
    "        for emo in emo_lookup[word]:\n",
    "          story_emotions[emo] += story[word]  #add the count of the word (see b-o-w) to the positive/negative counter in story_emotions\n",
    "    emo_presence.append([story_emotions[e] for e in emotions]) #adds positive and negative counts for each text of the corpus to the emo_presence list\n",
    "\n",
    "emo_presence = pd.DataFrame(emo_presence, columns=emotions)\n",
    "emo_presence.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb1berLOobtO"
   },
   "source": [
    "### Analysing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1750687301254,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "0QwLuljBfSGy",
    "outputId": "71805ad5-ffb5-4d1e-ea70-eea929a3e3b4"
   },
   "outputs": [],
   "source": [
    "emo_presence.sum(axis=0).sort_values().plot.barh();\n",
    "#surprisingly, positive words are more common than negative ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60-v-j6Lqkvw"
   },
   "source": [
    "Apply normalisation so that text length does not affect the results of our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1750687301986,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "dsAOTkP-pD6Z",
    "outputId": "ef751b53-6709-4ee7-eee8-c07f1de7eaf9"
   },
   "outputs": [],
   "source": [
    "horror['word_count'] = [sum(l.values()) for l in horror['bow']] #For each story (=row), sum the counts in the bag-of-words\n",
    "horror.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750687301994,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "dVcwsTBzpD9a",
    "outputId": "2c8e7146-724a-43f2-aeae-c5fb71ac5ee7"
   },
   "outputs": [],
   "source": [
    "#Create a seperate dataframe for the normalised data\n",
    "norm_emo_presence = pd.DataFrame()\n",
    "for emo in emo_presence:\n",
    "    norm_emo_presence.loc[:, emo] = (emo_presence[emo] / horror['word_count']).fillna(0)\n",
    "norm_emo_presence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13XWWoSxtNgQ"
   },
   "source": [
    "The top ten most emotional text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1750687302302,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "iW1sZ-fGpEAI",
    "outputId": "093a86a3-2944-4f81-ab9d-b300c5535afb"
   },
   "outputs": [],
   "source": [
    "#ten stories with the highest sum of normalised positive and negative values.\n",
    "#In other words, which ten stories consists of the most words associated with positive or negative sentiments.\n",
    "horror.loc[norm_emo_presence.sum(axis=1).sort_values(ascending=False)[:10].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dz8tbBquIc-"
   },
   "source": [
    "Top ten least emotional texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750687302309,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "mEJ_FIswpECv",
    "outputId": "3e1c9420-a26a-4425-cf92-c8f31d8c9185"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo_presence.sum(axis=1).sort_values(ascending=True)[:10].index]\n",
    "#Shows the ten texts that include the least words associated with a positive or negative emotion (= the least emotional texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYQffjXCoeAA"
   },
   "source": [
    "Top ten most positive texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 1206,
     "status": "ok",
     "timestamp": 1750687303517,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "yHAJVUdofSVZ",
    "outputId": "3c9f9063-eec2-4f57-df99-c1881ceeae7b"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo_presence['positive'].sort_values(ascending=False)[:10].index] #The ten most positive texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMXHxPEDuWZm"
   },
   "source": [
    "Top ten most negative texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1750687303559,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "CW0f86A7fSYC",
    "outputId": "18e1a675-41e6-453b-aa0b-0a9fa1591287"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo_presence['negative'].sort_values(ascending=False)[:10].index] #The ten most negative texts\n",
    "#Stories by Robert E. Howard appear notably often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pzKn3gsB4-3"
   },
   "source": [
    "### Visualizing possible correlations with scatter plots\n",
    "\n",
    "Initial observations in the top-10s:\n",
    "- high emotional intensity/positive ~ earlier publication, longer texts\n",
    "- low emotional intensity/negative ~ later publication, shorter texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750687303568,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "AnJkLeYSB4-3",
    "outputId": "5a882f66-6f19-4aa2-fd7f-fd40d150e051"
   },
   "outputs": [],
   "source": [
    "# calculate emotional intensity values\n",
    "horror['emotional_intensity'] = norm_emo_presence['positive'] + norm_emo_presence['negative']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# convert 'year' to numeric\n",
    "horror['year'] = pd.to_numeric(horror['year'], errors='coerce')\n",
    "\n",
    "# color the datapoints by length\n",
    "length_categories = horror['length'].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(length_categories)))\n",
    "for cat, color in zip(length_categories, colors):\n",
    "    subset = horror[horror['length'] == cat]\n",
    "    plt.scatter(\n",
    "        subset['year'],\n",
    "        subset['emotional_intensity'],\n",
    "        color=color,\n",
    "        alpha=0.7,\n",
    "        label=cat\n",
    "    )\n",
    "\n",
    "plt.xticks([1800, 1850, 1900, 1950])\n",
    "plt.title('Emotional Intensity ~ Year of Publication ~ Length')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Emotional Intensity')\n",
    "plt.legend(title='Length')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baRawyAyB4-3"
   },
   "source": [
    "Observations:\n",
    "- The emotional intensity across the genre seems to be **declining** over the time period in question.\n",
    "- The plot also reflects that most short stories and novellas in the dataset falls into the period 1900-1950, meaning that if we observe a trend in this group of texts, it might be due to length/time/even author.\n",
    "- On the other hand, novels are relatively evenly distributed across the timespan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LQBswVN5hp4"
   },
   "source": [
    "### Clustering\n",
    "We use Ward's linkage to cluster horror stories with similar positive/negative sentiment patterns. The Euclidian distance is used to calculate the distance between the stories. The smaller the distance between stories is, the more similar they are.\n",
    " - Generally, shorter texts / longer texts cluster together respectively\n",
    " - The earliest works are rather close to each other\n",
    " - Works from the same author, e.g., Lovecraft/Howard, are close to each other (for the 17 authors with more than 1 works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2294,
     "status": "ok",
     "timestamp": 1750687305865,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "PeSnQBjU5jbx",
    "outputId": "9c00b9d4-669f-4c5e-90d5-5718b8038558"
   },
   "outputs": [],
   "source": [
    "# colored according to length\n",
    "\n",
    "import scipy.spatial.distance as scidist\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "# Visualize\n",
    "def plot_tree_noveltype(linkage_object, labels, lengthlist, figsize=(10, 40), ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    with plt.rc_context({'lines.linewidth': 1.0}):\n",
    "        dendrogram = hierarchy.dendrogram(\n",
    "            linkage_object, labels=labels, ax=ax,\n",
    "            link_color_func=lambda c: 'black',\n",
    "            orientation='left',\n",
    "            leaf_font_size=10)\n",
    "    #print(dendrogram.keys())\n",
    "    # Remove ticks and spines\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    for s in ax.spines.values():\n",
    "        s.set_visible(False)\n",
    "    #add color based on length (novel vs novella vs short story vs novelette)\n",
    "    for label in ax.get_yticklabels():\n",
    "      story_title = label.get_text()\n",
    "      idx_title = labels.index(story_title) #get the idx for the story title from our list of titles\n",
    "      if lengthlist[idx_title] == 'novella':   #use the idx nr to assign a colour based on novel length\n",
    "          label.set_color('red')\n",
    "      elif lengthlist[idx_title] == 'short story':\n",
    "          label.set_color('blue')\n",
    "      elif lengthlist[idx_title] == 'novel':\n",
    "          label.set_color('green')\n",
    "      elif lengthlist[idx_title] == 'novelette':\n",
    "          label.set_color('orange')\n",
    "      else:\n",
    "          label.set_color('black')\n",
    "    #add a legend\n",
    "    legend_length_types = [\n",
    "        Patch(color='red', label='novella'),\n",
    "        Patch(color='blue', label='short story'),\n",
    "        Patch(color='green', label='novel'),\n",
    "        Patch(color='orange', label='novelette')\n",
    "        ]\n",
    "    plt.legend(handles=legend_length_types, title=\"Length Type\", loc='upper left')\n",
    "\n",
    "\n",
    "# 1. Calculate pairwise distances (based on the distribution of the positive/negative emotions for each story)\n",
    "dm = scidist.pdist(norm_emo_presence, 'euclidean')\n",
    "\n",
    "# 2. Establish branch structure (linkage_object, linking the most similar texts)\n",
    "linkage_object = hierarchy.linkage(dm, method='ward')\n",
    "\n",
    "# below is a version which also displays the authors:\n",
    "def format_authors(row):\n",
    "    # Check if author2 exists and is not NaN/empty\n",
    "    if pd.notna(row['author2']) and row['author2'] != '':\n",
    "        return f\"{row['author1']} & {row['author2']}\"\n",
    "    else:\n",
    "        return row['author1']\n",
    "\n",
    "horror['all_authors'] = horror.apply(format_authors, axis=1)\n",
    "combined_labels = [f\"{title} ({authors})\" for title, authors in zip(titles, horror['all_authors'])]\n",
    "\n",
    "plot_tree_noveltype(linkage_object, combined_labels, length) # titles instead of combined_labels for the version without authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2749,
     "status": "ok",
     "timestamp": 1750687308617,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "9b-SMntLd1cI",
    "outputId": "6002d287-72d7-4e08-feed-b298f101ff3e"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plot it with a heatmap\n",
    "dendro_heatmap = sns.clustermap(\n",
    "    norm_emo_presence,\n",
    "    row_linkage=linkage_object,\n",
    "    col_cluster=False, #no dendrogram for the columns (at the top of heatmap)\n",
    "    yticklabels=combined_labels,\n",
    "    cmap='coolwarm',\n",
    "    figsize=(15, 27)\n",
    ")\n",
    "\n",
    "#add color based on length (novel vs novella vs short story vs novelette)\n",
    "yticklabels = dendro_heatmap.ax_heatmap.get_yticklabels()\n",
    "for label in yticklabels:\n",
    "  story_title = label.get_text()\n",
    "  idx_title = combined_labels.index(story_title) #get the idx for the story title from our list of titles\n",
    "  if length[idx_title] == 'novella':   #use the idx nr to assign a colour based on novel length\n",
    "      label.set_color('red')\n",
    "  elif length[idx_title] == 'short story':\n",
    "      label.set_color('blue')\n",
    "  elif length[idx_title] == 'novel':\n",
    "      label.set_color('green')\n",
    "  elif length[idx_title] == 'novelette':\n",
    "      label.set_color('orange')\n",
    "  else:\n",
    "      label.set_color('black')\n",
    "#add a legend\n",
    "legend_length_types = [\n",
    "    Patch(color='red', label='novella'),\n",
    "    Patch(color='blue', label='short story'),\n",
    "    Patch(color='green', label='novel'),\n",
    "    Patch(color='orange', label='novelette')\n",
    "    ]\n",
    "dendro_heatmap.ax_heatmap.legend(\n",
    "    handles=legend_length_types,\n",
    "    title=\"Length Type\",\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(2, 1) #adjust this to manually move the legend\n",
    ")\n",
    "\n",
    "#need to flip the heatmap and the dendrogram horizontally to have the same bottom-up order as the previous code (since we specified 'orientation=left' there)\n",
    "dendro_heatmap.ax_heatmap.invert_yaxis()\n",
    "dendro_heatmap.ax_row_dendrogram.invert_yaxis()\n",
    "\n",
    "dendro_heatmap.ax_cbar.set_position((0.9, 0, .03, .09)) #adjust the position of the colourbar\n",
    "dendro_heatmap.ax_cbar.set_title('colourbar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1687,
     "status": "ok",
     "timestamp": 1750687310307,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "zZF4sCu95jeR",
    "outputId": "6d276cb8-8a93-4e4b-dcb2-871bf4abce08"
   },
   "outputs": [],
   "source": [
    "# according to year\n",
    "\n",
    "def plot_tree_yeargroups(linkage_object, labels, yearlist, figsize=(10, 40), ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    with plt.rc_context({'lines.linewidth': 1.0}):\n",
    "        dendrogram = hierarchy.dendrogram(\n",
    "            linkage_object, labels=labels, ax=ax,\n",
    "            link_color_func=lambda c: 'black',\n",
    "            orientation='left',\n",
    "            leaf_font_size=10)\n",
    "\n",
    "    # Remove ticks and spines\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    for s in ax.spines.values():\n",
    "        s.set_visible(False)\n",
    "\n",
    "    # Add color based on year ranges\n",
    "    for label in ax.get_yticklabels():\n",
    "        story_title = label.get_text()\n",
    "        idx_title = labels.index(story_title)\n",
    "        year = int(yearlist[idx_title])  # Convert to integer\n",
    "\n",
    "        if year < 1800:\n",
    "            label.set_color('purple')\n",
    "        elif 1800 <= year <= 1849:\n",
    "            label.set_color('blue')\n",
    "        elif 1850 <= year <= 1899:\n",
    "            label.set_color('green')\n",
    "        elif 1900 <= year <= 1949:\n",
    "            label.set_color('orange')\n",
    "        elif 1950 <= year <= 1999:\n",
    "            label.set_color('red')\n",
    "        else:\n",
    "            label.set_color('black')\n",
    "\n",
    "    #add a legend\n",
    "    legend_years = [\n",
    "        Patch(color='purple', label='before 1800'),\n",
    "        Patch(color='blue', label='1800-1849'),\n",
    "        Patch(color='green', label='1850-1899'),\n",
    "        Patch(color='orange', label='1900-1949'),\n",
    "        Patch(color='red', label='1950-1999'),\n",
    "        Patch(color='black', label='after 1999')\n",
    "        ]\n",
    "    plt.legend(handles=legend_years, title=\"Period\", loc='upper left')\n",
    "\n",
    "dm = scidist.pdist(norm_emo_presence, 'euclidean')\n",
    "linkage_object = hierarchy.linkage(dm, method='ward')\n",
    "\n",
    "plot_tree_yeargroups(linkage_object, combined_labels, horror['year']) # used the year column from the horror dataframe directly, in which values were converted to numeric (when making the scatter plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1673,
     "status": "ok",
     "timestamp": 1750687311982,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "rSWUUHBqnE6n",
    "outputId": "2bf16c1d-9086-4d26-c998-2e33fb0578ce"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plot it with a heatmap\n",
    "dendro_heatmap = sns.clustermap(\n",
    "    norm_emo_presence,\n",
    "    row_linkage=linkage_object,\n",
    "    col_cluster=False, #no dendrogram for the columns (at the top of heatmap)\n",
    "    yticklabels=combined_labels,\n",
    "    cmap='coolwarm',\n",
    "    figsize=(15, 27)\n",
    ")\n",
    "\n",
    "#add color based on year ranges\n",
    "yticklabels = dendro_heatmap.ax_heatmap.get_yticklabels()\n",
    "for label in yticklabels:\n",
    "    story_title = label.get_text()\n",
    "    idx_title = combined_labels.index(story_title)\n",
    "    year = int(horror['year'][idx_title])  # Convert to integer\n",
    "\n",
    "    if year < 1800:\n",
    "        label.set_color('purple')\n",
    "    elif 1800 <= year <= 1849:\n",
    "        label.set_color('blue')\n",
    "    elif 1850 <= year <= 1899:\n",
    "        label.set_color('green')\n",
    "    elif 1900 <= year <= 1949:\n",
    "        label.set_color('orange')\n",
    "    elif 1950 <= year <= 1999:\n",
    "        label.set_color('red')\n",
    "    else:\n",
    "        label.set_color('black')\n",
    "\n",
    "#add a legend\n",
    "legend_years = [\n",
    "    Patch(color='purple', label='before 1800'),\n",
    "    Patch(color='blue', label='1800-1849'),\n",
    "    Patch(color='green', label='1850-1899'),\n",
    "    Patch(color='orange', label='1900-1949'),\n",
    "    Patch(color='red', label='1950-1999'),\n",
    "    Patch(color='black', label='after 1999')\n",
    "    ]\n",
    "\n",
    "dendro_heatmap.ax_heatmap.legend(\n",
    "    handles=legend_years,\n",
    "    title=\"Length Type\",\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(2, 1) #adjust this to manually move the legend\n",
    ")\n",
    "\n",
    "#need to flip the heatmap and the dendrogram horizontally to have the same bottom-up order as the previous code (since we specified 'orientation=left' there)\n",
    "dendro_heatmap.ax_heatmap.invert_yaxis()\n",
    "dendro_heatmap.ax_row_dendrogram.invert_yaxis()\n",
    "\n",
    "dendro_heatmap.ax_cbar.set_position((0.9, 0, .03, .09)) #adjust the position of the colourbar\n",
    "dendro_heatmap.ax_cbar.set_title('colourbar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9APEsKE6v2r_"
   },
   "source": [
    "## Diachronic sentiment analysis (emotional arcs of the stories)\n",
    "based on positive/negative emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOrEp_KbCkMO"
   },
   "source": [
    "### sentence-level:\n",
    "\n",
    "Plotting emotional arcs at sentence level requires the original sentences (punctuation) to be preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750687311988,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "K07NIwKwAr9L"
   },
   "outputs": [],
   "source": [
    "# Reread the horror dataframe:\n",
    "with open('horror_tales_data_complete.json') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "#Create dataframe\n",
    "horror_raw = pd.DataFrame(corpus)\n",
    "\n",
    "# convert year to numeric\n",
    "horror_raw['year'] = pd.to_numeric(horror_raw['year'], errors='coerce')\n",
    "\n",
    "stories_raw = [] #list of stories (raw text)\n",
    "titles = [] #list of matching titles\n",
    "length = [] #list of lengths\n",
    "for index, row in horror_raw.iterrows():\n",
    "  stories_raw.append(row['text'])\n",
    "  titles.append(row['title'])\n",
    "  length.append(row['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1750687312063,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "zlI_hGqXu2SX"
   },
   "outputs": [],
   "source": [
    "# NRC Lexicon and look-up dictionary\n",
    "emo = pd.read_csv('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None)\n",
    "emo.columns = ['word', 'emotion', 'score']\n",
    "emo = emo[emo['emotion'].isin({'positive', 'negative'})] #limit to 'positive' and 'negative'\n",
    "emo = emo[emo['score'] != 0]\n",
    "emo.sample(5)   #df with word and corresponding negative or positive sentiment\n",
    "\n",
    "#This look-up dictionary only maps a single sentiment to words\n",
    "word2sent = dict(zip(emo['word'], emo['emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1750687312133,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "IwzCiStVC_y7"
   },
   "outputs": [],
   "source": [
    "# function for DCT\n",
    "from scipy.fftpack import dct\n",
    "def get_dct_transform(raw_values, low_pass_size=5, x_reverse_len=100, scale_vals=False, scale_range=False):\n",
    "    if not isinstance(raw_values, (list, np.ndarray)):\n",
    "        raise ValueError(\"Input must be a numeric list or numpy array\")\n",
    "    raw_values = np.array(raw_values)\n",
    "    if low_pass_size > len(raw_values):\n",
    "        raise ValueError(\"low_pass_size must be less than or equal to the length of raw_values input vector\")\n",
    "\n",
    "    values_dct = dct(raw_values, norm='ortho')\n",
    "    keepers = values_dct[:low_pass_size]\n",
    "    padded_keepers = np.concatenate([keepers, np.zeros(x_reverse_len - low_pass_size)])\n",
    "    dct_out = dct(padded_keepers, type=3, norm='ortho')\n",
    "\n",
    "    if scale_vals and scale_range:\n",
    "        raise ValueError(\"ERROR: scale_vals and scale_range cannot both be true.\")\n",
    "    if scale_vals:\n",
    "        return (dct_out - np.mean(dct_out)) / np.std(dct_out)\n",
    "    if scale_range:\n",
    "        return (dct_out - np.min(dct_out)) / (np.max(dct_out) - np.min(dct_out))\n",
    "\n",
    "    return dct_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1750687312161,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "qaC2_FK8r3BN"
   },
   "outputs": [],
   "source": [
    "def sentiment_plots_sentence_level(texts, labels, dct=False):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "    for text, label in zip(texts, labels):\n",
    "        df2 = pd.DataFrame(sent_tokenize(text), columns=['sentence']) #tokenizing at sentence level\n",
    "        #Preprocessing the sentences\n",
    "        df2['clean_sentence'] = df2['sentence'].str.lower().str.strip()\n",
    "        df2['clean_sentence'] = [''.join([c for c in t if (c.isalpha() or c.isspace())]) for t in df2['clean_sentence']]\n",
    "        df2['vocabulary'] = df2['clean_sentence'].str.split().apply(set) #Creating a vocabulary of unique words for each sentence\n",
    "\n",
    "        #Calculate the sentiment (positive & negative) scores for the vocabulary of each sentence and store them in a dataframe\n",
    "        sentiment_scores = []\n",
    "        for bow in df2['vocabulary']:\n",
    "            sent_cnts = Counter()\n",
    "            for word in bow:\n",
    "                if word in word2sent:\n",
    "                    sent_cnts[word2sent[word]] += 1\n",
    "            sentiment_scores.append([sent_cnts[e] for e in emotions])\n",
    "\n",
    "        df2 = pd.concat([df2, pd.DataFrame(sentiment_scores, columns=emotions)]).fillna(0)\n",
    "        df2['valence'] = df2['positive'] - df2['negative'] #Calculate the valence score for each sentence\n",
    "\n",
    "        if not dct:\n",
    "            df2['moving_average'] = df2['valence'].rolling(window=len(df2) // 10).mean()\n",
    "            df2['position'] = df2.index / len(df2)\n",
    "            df2.plot('position', 'moving_average', ax=ax, label=label)\n",
    "        else:   #If dct=True then the DCT transformation will be applied.\n",
    "            transformed_values = get_dct_transform(df2['valence'].values, x_reverse_len=100)\n",
    "            plt.plot(transformed_values, label=label)\n",
    "\n",
    "    plt.axhline(0, ls='--', c='lightgrey')\n",
    "    plt.xlabel('Narrative Time', fontsize=12)\n",
    "    plt.ylabel('Emotional Valence', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMmhzKnVAr9M"
   },
   "source": [
    "sentiment plot for one work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1750687312649,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "mRC-86Dzz7cj",
    "outputId": "d13850f4-b5e5-4458-f13e-8f2601b1d607"
   },
   "outputs": [],
   "source": [
    "sentiment_plots_sentence_level([stories_raw[2]], [titles[2]], dct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_Jl8NIWwE5F"
   },
   "source": [
    "sentiment plots for each segment of 50 years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 2968,
     "status": "ok",
     "timestamp": 1750687315614,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "Hrurm49gwIg2",
    "outputId": "8185a49d-a9d3-4f50-d894-4a2aed606f88"
   },
   "outputs": [],
   "source": [
    "#filter by 50-year timespans:\n",
    "horror_bf1800 = horror_raw[horror_raw[\"year\"] < 1800]\n",
    "\n",
    "bf1800_stories = horror_bf1800[\"text\"].tolist()\n",
    "bf1800_titles = horror_bf1800[\"title\"].tolist()\n",
    "\n",
    "sentiment_plots_sentence_level(bf1800_stories, bf1800_titles, dct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oraaIBfH0aPU"
   },
   "source": [
    "Sentiment plots based on length type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750687315618,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "uKWfFd5e0Zlk"
   },
   "outputs": [],
   "source": [
    "# horror_novels = horror[horror[\"length\"] == \"novel\"]\n",
    "# novels_stories = horror_novels[\"text\"].tolist()\n",
    "# novels_titles = horror_novels[\"title\"].tolist()\n",
    "# sentiment_plots_sentence_level(novels_stories, novels_titles, dct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 3680,
     "status": "ok",
     "timestamp": 1750687319302,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "U5fi25HNAr9M",
    "outputId": "344c0d07-38f8-472d-83b1-6492eec98e2c"
   },
   "outputs": [],
   "source": [
    "# plots with all works from one length category/time period are likely to be very cluttered.\n",
    "# we can specify both the length and the year of publication.\n",
    "\n",
    "df_to_plot = horror_raw[(horror_raw['length'] == 'novel') &\n",
    "                 (horror_raw['year'] > 1750) &\n",
    "                 (horror_raw['year'] < 1800)]\n",
    "\n",
    "if len(df_to_plot) > 0:\n",
    "    sentiment_plots_sentence_level(df_to_plot['text'].tolist(), df_to_plot['title'].tolist(), dct=False)\n",
    "else:\n",
    "    print(\"No stories found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81FNJj75Ltua"
   },
   "source": [
    "### chunk-level:\n",
    "It is also possible to try to split the texts into a fixed number of chunks for all texts (instead of sentences/paragraphs). This way, the plots of short/long texts won't seem to differ too much in granularity and will become more comparable, and the shape of the curve (roughly) remains. However, this approach could also be problematic because chunking may split sentences or narrative sequences, and for short/long texts, 1 chunk = different length/\"unit\"/narrative function, etc.\n",
    "\n",
    "The function below works on already preprocessed texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750687319307,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "jtRl1vM-8Kkb"
   },
   "outputs": [],
   "source": [
    "def sentiment_plots(texts, labels, dct=False):\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "    for text, label in zip(texts, labels):\n",
    "        # Split text into 100 equal-length chunks by word count\n",
    "        words = text.split()\n",
    "        total_words = len(words)\n",
    "        chunk_sizes = [total_words // 100 + (1 if i < total_words % 100 else 0) for i in range(100)]\n",
    "\n",
    "        chunks = []\n",
    "        start_idx = 0\n",
    "        for size in chunk_sizes:\n",
    "            end_idx = start_idx + size\n",
    "            chunk = ' '.join(words[start_idx:end_idx]) if start_idx < total_words else ''\n",
    "            chunks.append(chunk)\n",
    "            start_idx = end_idx\n",
    "\n",
    "        df = pd.DataFrame(chunks, columns=['chunk'])\n",
    "        df['vocabulary'] = df['chunk'].str.split().apply(set)\n",
    "\n",
    "        sentiment_scores = []\n",
    "        for bow in df['vocabulary']:\n",
    "            sent_cnts = Counter()\n",
    "            for word in bow:\n",
    "                if word in word2sent:\n",
    "                    sent_cnts[word2sent[word]] += 1\n",
    "            sentiment_scores.append([sent_cnts[e] for e in emotions])\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(sentiment_scores, columns=emotions)]).fillna(0)\n",
    "        df['valence'] = df['positive'] - df['negative']\n",
    "\n",
    "        if not dct:\n",
    "            df['moving_average'] = df['valence'].rolling(window=len(df) // 10).mean()\n",
    "            df['position'] = df.index / len(df)\n",
    "            df_plot = df.dropna(subset=['moving_average'])\n",
    "            df_plot = df_plot[df_plot['moving_average'] != 0.0]\n",
    "            df_plot.plot('position', 'moving_average', ax=ax, label=label)\n",
    "        else:\n",
    "            transformed_values = get_dct_transform(df['valence'].values, x_reverse_len=100)\n",
    "            plt.plot(transformed_values, label=label)\n",
    "\n",
    "    plt.axhline(0, ls='--', c='lightgrey')\n",
    "    plt.xlabel('Narrative Time', fontsize=12)\n",
    "    plt.ylabel('Emotional Valence', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1750687319691,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "U74y7PSFpqRF",
    "outputId": "4f25488d-7601-4732-a8d5-0e4bc7fcb3ce"
   },
   "outputs": [],
   "source": [
    "# the function takes lists of texts and titles as input: for one text, \"create\" a list\n",
    "sentiment_plots([stories[2]], [titles[2]], dct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1750687320441,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "iXpDFMCZLtub",
    "outputId": "2f613e03-30b3-44bf-f05c-bbd5d5e9902b"
   },
   "outputs": [],
   "source": [
    "# for multiple texts, directly use (slices of) the lists:\n",
    "sentiment_plots(stories[0:3], titles[0:3], dct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFj-efIO4F0j"
   },
   "source": [
    "## Analysis based on 8 emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqYxWwRCcWsw"
   },
   "source": [
    "### NRC Lexicon and look-up dictionary (8 emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1750687320557,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "k0fBD_JccZYZ",
    "outputId": "3a0bc9f3-97cf-47c2-8121-a5ce4b5d35c5"
   },
   "outputs": [],
   "source": [
    "emo8 = pd.read_csv('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None)\n",
    "emo8.columns = ['word', 'emotion', 'score']\n",
    "emo8 = emo8[emo8['emotion'].isin({'positive', 'negative'}) == False] #exclude 'positive' and 'negative'\n",
    "emo8 = emo8[emo8['score'] != 0]\n",
    "emo8.sample(5)   #df with word and corresponding negative or positive sentiment\n",
    "emo8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1750687320574,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "U1BKyu95coT0",
    "outputId": "1faa0f8e-9e63-4927-ff6c-0a1618a63717"
   },
   "outputs": [],
   "source": [
    "emo8.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1750687320630,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "4F5H1OXlczPm"
   },
   "outputs": [],
   "source": [
    "#note: The following dictionary also takes into account when multiple emotions (positive AND negative) are associated with a word\n",
    "emotions8 = emo8['emotion'].unique()\n",
    "emo8_lookup = defaultdict(list)\n",
    "\n",
    "for w, e in zip(emo8['word'], emo8['emotion']):\n",
    "  emo8_lookup[w].append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750687320644,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "0VOL2T-DgBiD",
    "outputId": "f0c19af8-c279-43bd-8881-667f9775a147"
   },
   "outputs": [],
   "source": [
    "#test\n",
    "for word in 'love hate adore tenacious'.split():\n",
    "    print(word, ':', emo8_lookup[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1750687320909,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "be_1ZQ7igNMC",
    "outputId": "b7850a55-15cf-4e77-c828-eea3e703c0b7"
   },
   "outputs": [],
   "source": [
    "emo8_presence = []\n",
    "\n",
    "for story in tqdm(horror['bow']):\n",
    "    story_emotions8 = Counter()\n",
    "    for word in story:\n",
    "      if word in emo8_lookup:   #this needs to be added, not every word is in our lookup dictionary\n",
    "        for emotion in emo8_lookup[word]:\n",
    "          story_emotions8[emotion] += story[word]  #add the count of the word (see b-o-w) to the positive/negative counter in story_emotions\n",
    "    emo8_presence.append([story_emotions8[e] for e in emotions8]) #adds positive and negative counts for each text of the corpus to the emo_presence list\n",
    "\n",
    "emo8_presence = pd.DataFrame(emo8_presence, columns=emotions8)\n",
    "emo8_presence.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiSySLr6jUE9"
   },
   "source": [
    "### Analysis (distribution 8 emotions)\n",
    "- Trust, fear, anticipation and sadness as the top 4 emotions: confirms findings in previous study on Lovecraft's works and shows that it may be a general feature of horror fiction.\n",
    "- Distinctive personal style of an author: Robert Howard's works are remarkably associated with negative emotions, fear and sadness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1750687321117,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "ycdYJxJ8gnZd",
    "outputId": "9371e1e7-501f-47a0-aa8f-ba3524b5ee13"
   },
   "outputs": [],
   "source": [
    "emo8_presence.sum(axis=0).sort_values().plot.barh();\n",
    "#Trust, fear and anticipation are the most common in the entire corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1750687321124,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "N4k32TRzkE6b",
    "outputId": "d6ebf032-dcec-4dfa-e31d-937a0af68dc1"
   },
   "outputs": [],
   "source": [
    "#Create a seperate dataframe for the normalised data\n",
    "norm_emo8_presence = pd.DataFrame()\n",
    "for emotion in emo8_presence:\n",
    "    norm_emo8_presence.loc[:, emotion] = (emo8_presence[emotion] / horror['word_count']).fillna(0)\n",
    "norm_emo8_presence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGXytjIskicX"
   },
   "source": [
    "Top ten most emotional stories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1750687321379,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "eCnz4K1YkV7Y",
    "outputId": "6ca0d9be-dbc7-4114-abea-d9359e28c0e7"
   },
   "outputs": [],
   "source": [
    "#Ten stories that consists of the most words associated with our eight emotions.\n",
    "horror.loc[norm_emo8_presence.sum(axis=1).sort_values(ascending=False)[:10].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI6uF6rWk3Qs"
   },
   "source": [
    "Top ten least emotional texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1750687321395,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "m3GRaTtKkuTC",
    "outputId": "6d518594-0550-4894-97cd-b36219a15d27"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence.sum(axis=1).sort_values(ascending=True)[:10].index]\n",
    "#Shows the ten texts that include the least words associated with the 8 emotions (= the least emotional texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDk5A8fvlGlc"
   },
   "source": [
    "Top ten text associated with the emotion 'fear':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1750687321411,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "lovH87Zwk4tV",
    "outputId": "d821bac5-aa69-428e-b1fe-9b959d1e5267"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence['fear'].sort_values(ascending=False)[:10].index] #The ten most positive texts\n",
    "#Similary to the most negative texts, the stories by Robert E. Howard are very common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KF5sSrtln9I"
   },
   "source": [
    "Top ten texts that consist of the most words associated with 'joy':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1750687321442,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "GkXe6lcmlUP-",
    "outputId": "a949dba1-6597-4aac-f2cc-fc57d249dec3"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence['joy'].sort_values(ascending=False)[:10].index] #The ten most positive texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AdVgrlHmNGu"
   },
   "source": [
    "Top ten texts that consist of the most words associated with 'sadness':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1750687321569,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "VqhNsPnDlnDp",
    "outputId": "b0593c2c-ee8c-46ab-e622-ec353e5116a2"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence['sadness'].sort_values(ascending=False)[:10].index]\n",
    "#The stories by Robert E. Howard appear mutliple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PPb0feAJc7Q"
   },
   "source": [
    "Top ten texts that consist of the most words associated with 'disgust':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1750687321615,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "q9b4wme3I3X8",
    "outputId": "907e7d33-d065-4bdf-e019-ce603694f62e"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence['disgust'].sort_values(ascending=False)[:10].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rA1zP-YdJepR"
   },
   "source": [
    "Top ten texts that consist of the most words associated with 'anticipation':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1750687321696,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "yLqG6optI3f5",
    "outputId": "7edd4a03-d255-461b-87ef-173eed20ed2d"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence['anticipation'].sort_values(ascending=False)[:10].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXePUy9Yd-MS"
   },
   "source": [
    "Top ten texts that consist of the most words associated with 'trust':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1750687322261,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "vR5Hawmrd5la",
    "outputId": "1c79685a-85f1-447e-de44-c69652e301ea"
   },
   "outputs": [],
   "source": [
    "horror.loc[norm_emo8_presence['trust'].sort_values(ascending=False)[:10].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwT3_SkW0P_3"
   },
   "source": [
    "### Clustering (based on distribution of 8 emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1750687322278,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "9AQH2Djr_yJP",
    "outputId": "629dee77-2c5b-41df-db3e-a49dbefbe450"
   },
   "outputs": [],
   "source": [
    "length[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1750687323207,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "ik1YBl6vmKS-",
    "outputId": "2420c8ee-0285-4c09-c5af-3f1414c73162"
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as scidist\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize\n",
    "def plot_tree_noveltype(linkage_object, labels, lengthlist, figsize=(10, 40), ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    with plt.rc_context({'lines.linewidth': 1.0}):\n",
    "        dendrogram = hierarchy.dendrogram(\n",
    "            linkage_object, labels=labels, ax=ax,\n",
    "            link_color_func=lambda c: 'black',\n",
    "            orientation='left',\n",
    "            leaf_font_size=10)\n",
    "    #print(dendrogram.keys())\n",
    "    # Remove ticks and spines\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    for s in ax.spines.values():\n",
    "        s.set_visible(False)\n",
    "    #add color based on length (novel vs novella vs short story vs novelette)\n",
    "    for label in ax.get_yticklabels():\n",
    "      story_title = label.get_text()\n",
    "      idx_title = labels.index(story_title) #get the idx for the story title from our list of titles\n",
    "      if lengthlist[idx_title] == 'novella':   #use the idx nr to assign a colour based on novel length\n",
    "          label.set_color('red')\n",
    "      elif lengthlist[idx_title] == 'short story':\n",
    "          label.set_color('blue')\n",
    "      elif lengthlist[idx_title] == 'novel':\n",
    "          label.set_color('green')\n",
    "      elif lengthlist[idx_title] == 'novelette':\n",
    "          label.set_color('orange')\n",
    "      else:\n",
    "          label.set_color('black')\n",
    "    #add a legend\n",
    "    legend_length_types = [\n",
    "        Patch(color='red', label='novella'),\n",
    "        Patch(color='blue', label='short story'),\n",
    "        Patch(color='green', label='novel'),\n",
    "        Patch(color='orange', label='novelette')\n",
    "        ]\n",
    "    plt.legend(handles=legend_length_types, title=\"Length Type\", loc='upper left')\n",
    "\n",
    "\n",
    "# 1. Calculate pairwise distances (based on the distribution of the 8 emotions for each story)\n",
    "dm8 = scidist.pdist(norm_emo8_presence, 'euclidean')\n",
    "\n",
    "# 2. Establish branch structure (linkage_object, linking the most similar texts)\n",
    "linkage_object = hierarchy.linkage(dm8, method='ward')\n",
    "\n",
    "plot_tree_noveltype(linkage_object, titles, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1750687610921,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "GXoW6_8rr-IV",
    "outputId": "e13fa8df-476f-4292-b438-87eac2646b0f"
   },
   "outputs": [],
   "source": [
    "#plot it with a heatmap\n",
    "dendro_heatmap = sns.clustermap(\n",
    "    norm_emo8_presence,\n",
    "    row_linkage=linkage_object,\n",
    "    col_cluster=True, #Change this to False to remove dendrogram for the emotions (at the top of heatmap)\n",
    "    yticklabels=combined_labels,\n",
    "    cmap='coolwarm',\n",
    "    figsize=(15, 27)\n",
    ")\n",
    "\n",
    "#add color based on length (novel vs novella vs short story vs novelette)\n",
    "yticklabels = dendro_heatmap.ax_heatmap.get_yticklabels()\n",
    "for label in yticklabels:\n",
    "  story_title = label.get_text()\n",
    "  idx_title = combined_labels.index(story_title) #get the idx for the story title from our list of titles\n",
    "  if length[idx_title] == 'novella':   #use the idx nr to assign a colour based on novel length\n",
    "      label.set_color('red')\n",
    "  elif length[idx_title] == 'short story':\n",
    "      label.set_color('blue')\n",
    "  elif length[idx_title] == 'novel':\n",
    "      label.set_color('green')\n",
    "  elif length[idx_title] == 'novelette':\n",
    "      label.set_color('orange')\n",
    "  else:\n",
    "      label.set_color('black')\n",
    "#add a legend\n",
    "legend_length_types = [\n",
    "    Patch(color='red', label='novella'),\n",
    "    Patch(color='blue', label='short story'),\n",
    "    Patch(color='green', label='novel'),\n",
    "    Patch(color='orange', label='novelette')\n",
    "    ]\n",
    "dendro_heatmap.ax_heatmap.legend(\n",
    "    handles=legend_length_types,\n",
    "    title=\"Length Type\",\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(2, 1.) #adjust this to manually move the legend\n",
    ")\n",
    "\n",
    "#need to flip the heatmap and the dendrogram horizontally to have the same order as the output of the previous code (since we specified 'orientation=left' there)\n",
    "dendro_heatmap.ax_heatmap.invert_yaxis()\n",
    "dendro_heatmap.ax_row_dendrogram.invert_yaxis()\n",
    "\n",
    "dendro_heatmap.ax_cbar.set_position((0.9, 0, .03, .09)) #adjust the position of the colourbar\n",
    "dendro_heatmap.ax_cbar.set_title('colourbar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1750687612206,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "uXJCLG-UB4-_",
    "outputId": "f96a8324-3878-49fb-c1b6-4d56a2dd5ebb"
   },
   "outputs": [],
   "source": [
    "# colored according to year\n",
    "\n",
    "dm8 = scidist.pdist(norm_emo8_presence, 'euclidean')\n",
    "linkage_object = hierarchy.linkage(dm8, method='ward')\n",
    "\n",
    "plot_tree_yeargroups(linkage_object, titles, horror['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2050,
     "status": "ok",
     "timestamp": 1750687614258,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "LustBvgXsmtb",
    "outputId": "6796bc3f-b1f6-4db0-ab15-39918410de0a"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plot it with a heatmap\n",
    "dendro_heatmap = sns.clustermap(\n",
    "    norm_emo8_presence,\n",
    "    row_linkage=linkage_object,\n",
    "    col_cluster=True, #Change this to False to remove dendrogram for the emotions (at the top of heatmap)\n",
    "    yticklabels=combined_labels,\n",
    "    cmap='coolwarm',\n",
    "    figsize=(15, 27)\n",
    ")\n",
    "\n",
    "#add color based on year ranges\n",
    "yticklabels = dendro_heatmap.ax_heatmap.get_yticklabels()\n",
    "for label in yticklabels:\n",
    "    story_title = label.get_text()\n",
    "    idx_title = combined_labels.index(story_title)\n",
    "    year = int(horror['year'][idx_title])  # Convert to integer\n",
    "\n",
    "    if year < 1800:\n",
    "        label.set_color('purple')\n",
    "    elif 1800 <= year <= 1849:\n",
    "        label.set_color('blue')\n",
    "    elif 1850 <= year <= 1899:\n",
    "        label.set_color('green')\n",
    "    elif 1900 <= year <= 1949:\n",
    "        label.set_color('orange')\n",
    "    elif 1950 <= year <= 1999:\n",
    "        label.set_color('red')\n",
    "    else:\n",
    "        label.set_color('black')\n",
    "\n",
    "#add a legend\n",
    "legend_years = [\n",
    "    Patch(color='purple', label='before 1800'),\n",
    "    Patch(color='blue', label='1800-1849'),\n",
    "    Patch(color='green', label='1850-1899'),\n",
    "    Patch(color='orange', label='1900-1949'),\n",
    "    Patch(color='red', label='1950-1999'),\n",
    "    Patch(color='black', label='after 1999')\n",
    "    ]\n",
    "\n",
    "dendro_heatmap.ax_heatmap.legend(\n",
    "    handles=legend_years,\n",
    "    title=\"Length Type\",\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(2, 1) #adjust this to manually move the legend\n",
    ")\n",
    "\n",
    "#need to flip the heatmap and the dendrogram horizontally to have the same bottom-up order as the previous code (since we specified 'orientation=left' there)\n",
    "dendro_heatmap.ax_heatmap.invert_yaxis()\n",
    "dendro_heatmap.ax_row_dendrogram.invert_yaxis()\n",
    "\n",
    "dendro_heatmap.ax_cbar.set_position((0.9, 0, .03, .09)) #adjust the position of the colourbar\n",
    "dendro_heatmap.ax_cbar.set_title('colourbar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TNDL-s1pqRU"
   },
   "source": [
    "### Emotional arcs (based on the top 4 emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750687614268,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "eQZkLci7pqRU",
    "outputId": "2532b6d6-410a-4cbd-eee4-61a732a6c675"
   },
   "outputs": [],
   "source": [
    "top4emo = ['trust', 'fear', 'anticipation', 'sadness']\n",
    "\n",
    "emo4 = pd.read_csv('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None)\n",
    "emo4.columns = ['word', 'emotion', 'score']\n",
    "emo4 = emo4[emo4['emotion'].isin(top4emo)] #limit to top 4 emotions\n",
    "emo4 = emo4[emo4['score'] != 0]\n",
    "emo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750687614275,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "c-LliXEepqRU",
    "outputId": "4850038c-e00f-45d2-9e75-fd6ae596154d"
   },
   "outputs": [],
   "source": [
    "# check the scores:\n",
    "emo4.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1750687614406,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "ArkhhJNEpqRU"
   },
   "outputs": [],
   "source": [
    "# look-up dictionary:\n",
    "word2emotion = {}\n",
    "for _, row in emo4.iterrows():\n",
    "    word = row['word']\n",
    "    emotion = row['emotion']\n",
    "    if emotion in top4emo:\n",
    "        word2emotion[word] = emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1750687614458,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "YNnqy1XqpqRU"
   },
   "outputs": [],
   "source": [
    "def emo4_plot(text, label):\n",
    "    \"\"\"\n",
    "    Plot how the top 4 emotions change throughout a text.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to analyze\n",
    "        label (str): The title/label of the text\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "    # Define a color palette for the emotions\n",
    "    emotion_colors = {\n",
    "        top4emo[0]: 'red',      # trust\n",
    "        top4emo[1]: 'blue',     # fear\n",
    "        top4emo[2]: 'green',    # anticipation\n",
    "        top4emo[3]: 'purple'    # sadness\n",
    "    }\n",
    "\n",
    "    # Chunking\n",
    "    words = text.split()\n",
    "    total_words = len(words)\n",
    "    chunk_sizes = [total_words // 100 + (1 if i < total_words % 100 else 0) for i in range(100)]\n",
    "\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    for size in chunk_sizes:\n",
    "        end_idx = start_idx + size\n",
    "        chunk = ' '.join(words[start_idx:end_idx]) if start_idx < total_words else ''\n",
    "        chunks.append(chunk)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    df = pd.DataFrame(chunks, columns=['chunk'])\n",
    "    # Store chunk lengths for normalization\n",
    "    df['chunk_length'] = df['chunk'].apply(lambda x: len(x.split()))\n",
    "    df['vocabulary'] = df['chunk'].str.split().apply(set)\n",
    "\n",
    "    # Initialize emotion scores (0) for each chunk\n",
    "    for emotion in top4emo:\n",
    "        df[emotion] = 0.0\n",
    "\n",
    "    # Calculate emotion scores for each chunk\n",
    "    for i, bow in enumerate(df['vocabulary']):\n",
    "        for word in bow:\n",
    "            if word in word2emotion:\n",
    "                emotion = word2emotion[word]\n",
    "                if emotion in top4emo:\n",
    "                    df.at[i, emotion] += 1\n",
    "\n",
    "    # Normalize emotion scores by chunk length\n",
    "    for emotion in top4emo:\n",
    "        df[emotion] = df[emotion] / df['chunk_length']\n",
    "\n",
    "    df['position'] = df.index / len(df)\n",
    "\n",
    "    for emotion in top4emo:\n",
    "        df[f'{emotion}_smooth'] = df[emotion].rolling(window=max(len(df)//10, 1),\n",
    "                                                     min_periods=1).mean()\n",
    "\n",
    "        ax.plot(df['position'], df[f'{emotion}_smooth'],\n",
    "                label=emotion,\n",
    "                color=emotion_colors[emotion],\n",
    "                linewidth=2)\n",
    "\n",
    "    plt.title(f'Top 4 Emotion Trajectories in \"{label}\"', fontsize=14)\n",
    "    plt.xlabel('Narrative Time', fontsize=12)\n",
    "    plt.ylabel('Emotion Intensity', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1750687614860,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "kYWe3yi5pqRV",
    "outputId": "6097a7d1-48ce-475e-e13a-1f40c706bac1"
   },
   "outputs": [],
   "source": [
    "# for an individual text:\n",
    "emo4_plot(stories[2], titles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 60077,
     "status": "ok",
     "timestamp": 1750687846580,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "arIwo4LlpqRV",
    "outputId": "32999f77-a2d0-4f6b-b4d8-d978cc642208"
   },
   "outputs": [],
   "source": [
    "#for multiple texts\n",
    "for i in range(118):\n",
    "    emo4_plot(stories[i], titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 58136,
     "status": "ok",
     "timestamp": 1750687904722,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "ADYoqW3jHSu5",
    "outputId": "c3e00f01-566c-48db-c415-7fd6fdc73551"
   },
   "outputs": [],
   "source": [
    "for entry in ['short story', 'novel', 'novella', 'novelette']:\n",
    "    print(f\"\\n_______\\nPlots for {entry}:\\n_______\\n\")\n",
    "\n",
    "    for i in range(len(length)):\n",
    "        if length[i] == entry:\n",
    "            emo4_plot(stories[i], titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750687904729,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "MV16Mle2HS4P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750687904745,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "5DHQHrQxHXrF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750687904750,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "lervvfKGHXug",
    "outputId": "a5567fad-3596-40c0-b2f9-7ed5c2845e23"
   },
   "outputs": [],
   "source": [
    "#Two least common emotions\n",
    "bottom2emo = ['surprise', 'disgust']\n",
    "\n",
    "emo2 = pd.read_csv('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None)\n",
    "emo2.columns = ['word', 'emotion', 'score']\n",
    "emo2 = emo2[emo2['emotion'].isin(bottom2emo)] #limit to bottom 2 emotions\n",
    "emo2 = emo2[emo2['score'] != 0]\n",
    "emo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750687904756,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "UZ1TPha3HZbR"
   },
   "outputs": [],
   "source": [
    "# look-up dictionary:\n",
    "word2emotion = {}\n",
    "for _, row in emo2.iterrows():\n",
    "    word = row['word']\n",
    "    emotion = row['emotion']\n",
    "    if emotion in bottom2emo:\n",
    "        word2emotion[word] = emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750687904763,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "WuiINhgxHZeY"
   },
   "outputs": [],
   "source": [
    "def emo2_plot(text, label):\n",
    "    \"\"\"\n",
    "    Plot how the bottom 2 emotions change throughout a text.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text to analyze\n",
    "        label (str): The title/label of the text\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "    # Define a color palette for the emotions\n",
    "    emotion_colors = {\n",
    "        bottom2emo[0]: 'red',      # surprise\n",
    "        bottom2emo[1]: 'blue'     # disgust\n",
    "    }\n",
    "\n",
    "    # Chunking\n",
    "    words = text.split()\n",
    "    total_words = len(words)\n",
    "    chunk_sizes = [total_words // 100 + (1 if i < total_words % 100 else 0) for i in range(100)]\n",
    "\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    for size in chunk_sizes:\n",
    "        end_idx = start_idx + size\n",
    "        chunk = ' '.join(words[start_idx:end_idx]) if start_idx < total_words else ''\n",
    "        chunks.append(chunk)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    df = pd.DataFrame(chunks, columns=['chunk'])\n",
    "    # Store chunk lengths for normalization\n",
    "    df['chunk_length'] = df['chunk'].apply(lambda x: len(x.split()))\n",
    "    df['vocabulary'] = df['chunk'].str.split().apply(set)\n",
    "\n",
    "    # Initialize emotion scores (0) for each chunk\n",
    "    for emotion in bottom2emo:\n",
    "        df[emotion] = 0.0\n",
    "\n",
    "    # Calculate emotion scores for each chunk\n",
    "    for i, bow in enumerate(df['vocabulary']):\n",
    "        for word in bow:\n",
    "            if word in word2emotion:\n",
    "                emotion = word2emotion[word]\n",
    "                if emotion in bottom2emo:\n",
    "                    df.at[i, emotion] += 1\n",
    "\n",
    "    # Normalize emotion scores by chunk length\n",
    "    for emotion in bottom2emo:\n",
    "        df[emotion] = df[emotion] / df['chunk_length']\n",
    "\n",
    "    df['position'] = df.index / len(df)\n",
    "\n",
    "    for emotion in bottom2emo:\n",
    "        df[f'{emotion}_smooth'] = df[emotion].rolling(window=max(len(df)//10, 1),\n",
    "                                                     min_periods=1).mean()\n",
    "\n",
    "        ax.plot(df['position'], df[f'{emotion}_smooth'],\n",
    "                label=emotion,\n",
    "                color=emotion_colors[emotion],\n",
    "                linewidth=2)\n",
    "\n",
    "    plt.title(f'Bottom 2 Emotion Trajectories in \"{label}\"', fontsize=14)\n",
    "    plt.xlabel('Narrative Time', fontsize=12)\n",
    "    plt.ylabel('Emotion Intensity', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 45604,
     "status": "ok",
     "timestamp": 1750687950375,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "JR8uUqgIHZgy",
    "outputId": "fe6b1f98-38f3-4687-c48b-1658f3a340b8"
   },
   "outputs": [],
   "source": [
    "#for multiple texts\n",
    "for i in range(118):\n",
    "    emo2_plot(stories[i], titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 45284,
     "status": "ok",
     "timestamp": 1750687995666,
     "user": {
      "displayName": "Anouck",
      "userId": "08644346140055373993"
     },
     "user_tz": -120
    },
    "id": "H4YAA1QMHZjJ",
    "outputId": "7148e076-641f-4b81-ae81-327b516985d3"
   },
   "outputs": [],
   "source": [
    "for entry in ['short story', 'novel', 'novella', 'novelette']:\n",
    "    print(f\"\\n_____\\nPlots for {entry}:\\n_____\\n\")\n",
    "\n",
    "    for i in range(len(length)):\n",
    "        if length[i] == entry:\n",
    "            emo2_plot(stories[i], titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLNVs78MHZlE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
